"""
FIN-R1æ¨¡å‹é›†æˆæ¨¡å—
è´Ÿè´£é›†æˆå’Œè°ƒç”¨FIN-R1å¤§è¯­è¨€æ¨¡å‹è¿›è¡ŒæŠ•èµ„éœ€æ±‚è§£æ
"""

import json
import os
from datetime import datetime
from typing import Any, Dict, List, Optional

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    import torch

    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False

try:
    from transformers import AutoModelForCausalLM, AutoTokenizer

    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False

try:
    import yaml

    HAS_YAML = True
except ImportError:
    HAS_YAML = False

from common.exceptions import ModelError
from common.logging_system import setup_logger
from common.model_inference_visualizer import (
    ModelInferenceVisualizer,
    display_model_info,
)
from module_10_ai_interaction.requirement_parser import (
    InvestmentConstraint,
    InvestmentGoal,
    InvestmentHorizon,
    ParsedRequirement,
    RequirementParser,
    RiskTolerance,
)

logger = setup_logger("fin_r1_integration")


class FINR1Integration:
    """FIN-R1æ¨¡å‹é›†æˆç±»"""

    def __init__(
        self, config: Optional[Dict[str, Any]] = None, config_path: Optional[str] = None
    ):
        """åˆå§‹åŒ–FIN-R1é›†æˆ

        Args:
            config: æ¨¡å‹é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        # åŠ è½½é…ç½®
        if config is None:
            if config_path is None:
                config_path = os.path.join(
                    "module_10_ai_interaction", "config", "fin_r1_config.yaml"
                )
            config = self._load_config(config_path)

        # ç¡®ä¿configæ˜¯å­—å…¸
        if config is None:
            config = {}

        self.config = config
        model_config = config.get("model", {})

        self.model_path = model_config.get("model_path", ".Fin-R1")
        self.device = model_config.get("device", "cpu")
        self.batch_size = model_config.get("batch_size", 1)
        self.max_length = model_config.get("max_length", 2048)
        self.temperature = model_config.get("temperature", 0.7)
        self.top_p = model_config.get("top_p", 0.9)
        self.top_k = model_config.get("top_k", 50)
        self.do_sample = model_config.get("do_sample", True)
        self.repetition_penalty = model_config.get("repetition_penalty", 1.1)

        # æç¤ºè¯æ¨¡æ¿
        self.prompts = config.get("prompts", {})

        # æ€§èƒ½é…ç½®
        performance_config = config.get("performance", {})
        self.timeout = performance_config.get("timeout", 30)
        self.max_retries = performance_config.get("max_retries", 3)

        # åˆå§‹åŒ–æ¨¡å‹å’Œåˆ†è¯å™¨
        self.model = None
        self.tokenizer = None
        self.requirement_parser = RequirementParser()

        # åˆå§‹åŒ–å¯è§†åŒ–å™¨
        self.visualizer = ModelInferenceVisualizer()

        self._load_model()

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„

        Returns:
            é…ç½®å­—å…¸
        """
        try:
            if HAS_YAML:
                import os

                # å¤„ç†ç›¸å¯¹è·¯å¾„
                if not os.path.isabs(config_path):
                    base_dir = os.path.dirname(
                        os.path.dirname(os.path.abspath(__file__))
                    )
                    config_path = os.path.join(base_dir, config_path)

                with open(config_path, "r", encoding="utf-8") as f:
                    config = yaml.safe_load(f)
                    # ç¡®ä¿è¿”å›å­—å…¸è€Œä¸æ˜¯Noneï¼ˆç©ºæ–‡ä»¶ä¼šè¿”å›Noneï¼‰
                    return config if config is not None else {}
            else:
                logger.warning("PyYAML not available, using default config")
                return {}
        except Exception as e:
            logger.warning(
                f"Failed to load config from {config_path}: {e}, using default"
            )
            return {}

    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            if not HAS_TRANSFORMERS or not HAS_TORCH:
                logger.warning(
                    "Transformers or PyTorch not available, using mock model"
                )
                self.model = None
                self.tokenizer = None
                return

            import os

            if not os.path.exists(self.model_path):
                logger.warning(
                    f"Model path {self.model_path} does not exist, using mock model"
                )
                self.model = None
                self.tokenizer = None
                return

            logger.info(f"Loading FIN-R1 model from {self.model_path}...")

            # æ˜¾ç¤ºåŠ è½½è¿›åº¦
            if self.visualizer and self.visualizer.console:
                self.visualizer.console.print(
                    "\n[bold cyan]ğŸš€ Initializing FIN-R1 Model[/bold cyan]\n"
                )

            # åŠ è½½åˆ†è¯å™¨
            logger.info("Loading tokenizer...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_path, trust_remote_code=True, use_fast=False
            )

            # è®¾ç½®pad_tokenï¼ˆå¦‚æœæœªè®¾ç½®ï¼‰
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token

            # åŠ è½½æ¨¡å‹ï¼ˆæ˜¾ç¤ºè¿›åº¦ï¼‰
            def load_model_with_progress(progress=None, task=None):
                model = AutoModelForCausalLM.from_pretrained(
                    self.model_path,
                    trust_remote_code=True,
                    dtype=torch.float32,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ dtype è€Œä¸æ˜¯ torch_dtype
                    low_cpu_mem_usage=True,  # å‡å°‘CPUå†…å­˜å ç”¨
                )
                if progress and task:
                    progress.update(task, advance=50)

                model.to(self.device)
                model.eval()

                if progress and task:
                    progress.update(task, advance=50)
                return model

            self.model = (
                self.visualizer.simple_progress_bar(
                    "[cyan]ğŸ“¦ Loading model weights",
                    total=100,
                    callback=load_model_with_progress,
                )
                if self.visualizer
                else load_model_with_progress()
            )

            logger.info("âœ… FIN-R1 model loaded successfully")

            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            display_model_info("FIN-R1", "7B")
        except Exception as e:
            logger.warning(f"Failed to load FIN-R1 model: {e}, using mock model")
            self.model = None
            self.tokenizer = None

    async def process_request(self, user_input: str) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚

        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬

        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        try:
            # 1. è§£æç”¨æˆ·éœ€æ±‚
            parsed_requirement = self.requirement_parser.parse_requirement(user_input)

            # 2. ä½¿ç”¨FIN-R1æ¨¡å‹è¿›è¡Œæ·±åº¦ç†è§£
            model_output = self._invoke_fin_r1_model(user_input, parsed_requirement)

            # 3. ç”Ÿæˆç­–ç•¥å‚æ•°
            strategy_params = self._generate_strategy_parameters(
                parsed_requirement, model_output
            )

            # 4. ç”Ÿæˆé£é™©å‚æ•°
            risk_params = self._generate_risk_parameters(parsed_requirement)

            # 5. ç»„åˆç»“æœ
            result = {
                "parsed_requirement": parsed_requirement.to_dict(),
                "model_output": model_output,
                "strategy_params": strategy_params,
                "risk_params": risk_params,
                "timestamp": datetime.now().isoformat(),
            }

            logger.info("Request processed successfully")
            return result

        except Exception as e:
            logger.error(f"Failed to process request: {e}")
            raise ModelError(f"Request processing failed: {e}")

    def _invoke_fin_r1_model(
        self, user_input: str, parsed_requirement: ParsedRequirement
    ) -> Dict[str, Any]:
        """è°ƒç”¨FIN-R1æ¨¡å‹

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            parsed_requirement: è§£æåçš„éœ€æ±‚

        Returns:
            æ¨¡å‹è¾“å‡º
        """
        try:
            # å¦‚æœæ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„æ–¹æ³•
            if self.model is None or self.tokenizer is None:
                logger.info("Using rule-based fallback (model not loaded)")
                return self._rule_based_analysis(user_input, parsed_requirement)

            # å‡†å¤‡è¾“å…¥
            input_text = self._prepare_model_input(user_input, parsed_requirement)

            logger.info(f"Invoking FIN-R1 model with input length: {len(input_text)}")

            # åˆ†è¯
            inputs = self.tokenizer(
                input_text,
                return_tensors="pt",
                max_length=self.max_length,
                padding=False,
                truncation=True,
            )

            # ç§»åŠ¨åˆ°è®¾å¤‡
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            # ğŸš€ ä½¿ç”¨æµå¼ç”Ÿæˆ + å¯è§†åŒ–è¿›åº¦
            logger.info("Starting model generation with visualization...")

            max_new_tokens = 50  # å¢åŠ åˆ°50ä»¥å±•ç¤ºè¿›åº¦

            try:
                # å°è¯•ä½¿ç”¨æµå¼ç”Ÿæˆï¼ˆå¦‚æœæ”¯æŒï¼‰
                from threading import Thread

                from transformers import TextIteratorStreamer

                # ğŸ”§ è®¾ç½® timeout é˜²æ­¢æ­»é”ï¼
                streamer = TextIteratorStreamer(
                    self.tokenizer,
                    skip_prompt=True,
                    skip_special_tokens=True,
                    timeout=30.0,  # ğŸ”‘ å…³é”®ï¼š30ç§’è¶…æ—¶ï¼Œé˜²æ­¢æ— é™ç­‰å¾…
                )

                # åœ¨åå°çº¿ç¨‹è¿è¡Œç”Ÿæˆ
                generation_kwargs = dict(
                    **inputs,
                    streamer=streamer,
                    max_new_tokens=max_new_tokens,
                    do_sample=False,  # ä½¿ç”¨è´ªå¿ƒè§£ç ï¼ˆæ›´å¿«ï¼‰
                    num_beams=1,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    use_cache=True,
                )

                # ğŸ”‘ å¿…é¡»å…ˆå¯åŠ¨ç”Ÿæˆçº¿ç¨‹
                thread = Thread(target=self.model.generate, kwargs=generation_kwargs)
                thread.start()

                # ğŸ”‘ ç«‹å³å¼€å§‹æ¶ˆè´¹ streamerï¼Œé¿å…æ­»é”
                logger.info("ğŸš€ Starting streaming generation...")

                # ğŸ¯ ä½¿ç”¨å¯è§†åŒ–å™¨æ˜¾ç¤ºæµå¼ç”Ÿæˆè¿›åº¦
                generated_text = self.visualizer.visualize_generation(
                    streamer, max_new_tokens=max_new_tokens, model_name="FIN-R1"
                )

                # ç­‰å¾…ç”Ÿæˆçº¿ç¨‹å®Œæˆ
                thread.join(timeout=60)  # æœ€å¤šç­‰å¾…60ç§’

                if thread.is_alive():
                    logger.warning("âš ï¸ Generation thread timeout, may be incomplete")
                    raise TimeoutError("Model generation timeout")

            except Exception as stream_error:
                # Fallback: éæµå¼ç”Ÿæˆï¼ˆå¸¦ç®€å•è¿›åº¦ï¼‰
                logger.warning(
                    f"Streaming not available: {stream_error}, using standard generation"
                )

                if self.visualizer and self.visualizer.console:
                    self.visualizer.console.print(
                        "[yellow]âš¡ Using fast non-streaming mode[/yellow]"
                    )

                with torch.no_grad():
                    outputs = self.model.generate(
                        **inputs,
                        max_new_tokens=max_new_tokens,
                        do_sample=False,
                        num_beams=1,
                        pad_token_id=self.tokenizer.pad_token_id,
                        eos_token_id=self.tokenizer.eos_token_id,
                        use_cache=True,
                    )

                generated_text = self.tokenizer.decode(
                    outputs[0], skip_special_tokens=True
                )

            logger.info("âœ… Model generation completed")

            # æå–è¾“å…¥åçš„ç”Ÿæˆéƒ¨åˆ†
            if input_text in generated_text:
                generated_text = generated_text.split(input_text)[-1].strip()

            logger.info(f"Model generated text: {generated_text[:200]}...")

            # âš ï¸ ç”±äºFIN-R1æ˜¯é€šç”¨æ¨¡å‹ï¼Œç”Ÿæˆçš„æ–‡æœ¬å¯èƒ½ä¸æ˜¯ç»“æ„åŒ–è¾“å‡º
            # æˆ‘ä»¬ä¸»è¦ä½¿ç”¨è§„åˆ™å¼•æ“çš„ç»“æœï¼Œæ¨¡å‹è¾“å‡ºä½œä¸ºè¾…åŠ©å‚è€ƒ
            logger.info("âš ï¸ æ³¨æ„ï¼šå½“å‰ä½¿ç”¨è§„åˆ™å¼•æ“+æ¨¡å‹è¾…åŠ©çš„æ··åˆæ¨¡å¼")

            # è§£æè¾“å‡ºï¼ˆä¸»è¦ä½¿ç”¨è§„åˆ™å¼•æ“ï¼‰
            model_output = self._rule_based_analysis(user_input, parsed_requirement)
            model_output["fin_r1_generated_text"] = (
                generated_text  # ä¿å­˜æ¨¡å‹ç”Ÿæˆæ–‡æœ¬ä½œä¸ºå‚è€ƒ
            )

            return model_output

        except Exception as e:
            logger.error(f"Failed to invoke FIN-R1 model: {e}")
            # ä½¿ç”¨åŸºäºè§„åˆ™çš„fallback
            return self._rule_based_analysis(user_input, parsed_requirement)

    def _rule_based_analysis(
        self, user_input: str, parsed_requirement: ParsedRequirement
    ) -> Dict[str, Any]:
        """åŸºäºè§„åˆ™çš„åˆ†æï¼ˆfallbackæ–¹æ³•ï¼‰

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            parsed_requirement: è§£æåçš„éœ€æ±‚

        Returns:
            åˆ†æç»“æœ
        """
        # åŸºäºé£é™©åå¥½ç¡®å®šç­–ç•¥
        strategy_map = {
            RiskTolerance.CONSERVATIVE: "conservative",
            RiskTolerance.MODERATE: "balanced",
            RiskTolerance.AGGRESSIVE: "growth",
            RiskTolerance.VERY_AGGRESSIVE: "aggressive",
        }

        strategy = strategy_map.get(parsed_requirement.risk_tolerance, "balanced")

        # é£é™©è¯„ä¼°
        risk_map = {
            RiskTolerance.CONSERVATIVE: "low",
            RiskTolerance.MODERATE: "moderate",
            RiskTolerance.AGGRESSIVE: "high",
            RiskTolerance.VERY_AGGRESSIVE: "very_high",
        }

        risk_assessment = risk_map.get(parsed_requirement.risk_tolerance, "moderate")

        # è¡Œä¸šåå¥½
        sector_preferences = []
        if any(
            "ç§‘æŠ€" in goal.description or "technology" in goal.description.lower()
            for goal in parsed_requirement.investment_goals
        ):
            sector_preferences.extend(["technology", "software"])
        if any(
            "åŒ»ç–—" in goal.description or "health" in goal.description.lower()
            for goal in parsed_requirement.investment_goals
        ):
            sector_preferences.extend(["healthcare", "biotech"])

        if not sector_preferences:
            sector_preferences = ["diversified"]

        return {
            "strategy_recommendation": strategy,
            "risk_assessment": risk_assessment,
            "confidence_score": 0.75,
            "market_outlook": "neutral",
            "sector_preferences": sector_preferences,
            "excluded_sectors": [],
            "analysis_method": "rule_based",
        }

    def _parse_model_output(
        self, generated_text: str, parsed_requirement: ParsedRequirement
    ) -> Dict[str, Any]:
        """è§£ææ¨¡å‹è¾“å‡º

        Args:
            generated_text: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
            parsed_requirement: è§£æåçš„éœ€æ±‚

        Returns:
            ç»“æ„åŒ–è¾“å‡º
        """
        # å°è¯•è§£æJSON
        try:
            import re

            json_match = re.search(r"\{[^{}]*\}", generated_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass

        # ä½¿ç”¨è§„åˆ™è§£æ
        output = self._rule_based_analysis("", parsed_requirement)
        output["raw_output"] = generated_text
        output["analysis_method"] = "model_generation"

        # å°è¯•ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
        text_lower = generated_text.lower()

        # ç­–ç•¥è¯†åˆ«
        if any(word in text_lower for word in ["ä¿å®ˆ", "conservative", "ç¨³å¥"]):
            output["strategy_recommendation"] = "conservative"
        elif any(word in text_lower for word in ["æ¿€è¿›", "aggressive", "è¿›å–"]):
            output["strategy_recommendation"] = "aggressive"
        elif any(word in text_lower for word in ["æˆé•¿", "growth"]):
            output["strategy_recommendation"] = "growth"

        # é£é™©è¯†åˆ«
        if any(word in text_lower for word in ["ä½é£é™©", "low risk"]):
            output["risk_assessment"] = "low"
        elif any(word in text_lower for word in ["é«˜é£é™©", "high risk"]):
            output["risk_assessment"] = "high"

        return output

    def _prepare_model_input(
        self, user_input: str, parsed_requirement: ParsedRequirement
    ) -> str:
        """å‡†å¤‡æ¨¡å‹è¾“å…¥

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            parsed_requirement: è§£æåçš„éœ€æ±‚

        Returns:
            æ¨¡å‹è¾“å…¥æ–‡æœ¬
        """
        # ä½¿ç”¨é…ç½®çš„æç¤ºè¯æ¨¡æ¿
        template = self.prompts.get("investment_analysis", "")

        if template:
            # æ ¼å¼åŒ–æ¨¡æ¿
            input_text = template.format(
                user_input=user_input,
                investment_amount=parsed_requirement.investment_amount or "æœªæŒ‡å®š",
                risk_tolerance=parsed_requirement.risk_tolerance.value
                if parsed_requirement.risk_tolerance
                else "æœªæŒ‡å®š",
                investment_horizon=parsed_requirement.investment_horizon.value
                if parsed_requirement.investment_horizon
                else "æœªæŒ‡å®š",
                investment_goals=", ".join(
                    [goal.goal_type for goal in parsed_requirement.investment_goals]
                )
                if parsed_requirement.investment_goals
                else "æœªæŒ‡å®š",
                constraints=", ".join(
                    [
                        constraint.constraint_type
                        for constraint in parsed_requirement.constraints
                    ]
                )
                if parsed_requirement.constraints
                else "æ— ",
            )
        else:
            # é»˜è®¤æ ¼å¼
            input_parts = [
                f"ç”¨æˆ·éœ€æ±‚ï¼š{user_input}",
                f"æŠ•èµ„é‡‘é¢ï¼š{parsed_requirement.investment_amount or 'æœªæŒ‡å®š'}",
                f"é£é™©åå¥½ï¼š{parsed_requirement.risk_tolerance.value if parsed_requirement.risk_tolerance else 'æœªæŒ‡å®š'}",
                f"æŠ•èµ„æœŸé™ï¼š{parsed_requirement.investment_horizon.value if parsed_requirement.investment_horizon else 'æœªæŒ‡å®š'}",
                f"æŠ•èµ„ç›®æ ‡ï¼š{[goal.goal_type for goal in parsed_requirement.investment_goals]}",
                f"çº¦æŸæ¡ä»¶ï¼š{[constraint.constraint_type for constraint in parsed_requirement.constraints]}",
            ]
            input_text = "\n".join(input_parts)

        return input_text

    def _generate_strategy_parameters(
        self, parsed_requirement: ParsedRequirement, model_output: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç­–ç•¥å‚æ•°

        Args:
            parsed_requirement: è§£æåçš„éœ€æ±‚
            model_output: æ¨¡å‹è¾“å‡º

        Returns:
            ç­–ç•¥å‚æ•°å­—å…¸
        """
        # åŸºäºè§£æç»“æœå’Œæ¨¡å‹è¾“å‡ºç”Ÿæˆç­–ç•¥å‚æ•°
        strategy_params = {
            "strategy_mix": {
                "trend_following": 0.3,
                "mean_reversion": 0.3,
                "momentum": 0.2,
                "value": 0.2,
            },
            "rebalance_frequency": "weekly",
            "position_sizing_method": "kelly_criterion",
            "risk_adjustment": True,
        }

        # æ ¹æ®é£é™©åå¥½è°ƒæ•´
        if parsed_requirement.risk_tolerance:
            if parsed_requirement.risk_tolerance == RiskTolerance.CONSERVATIVE:
                strategy_params["strategy_mix"] = {
                    "trend_following": 0.2,
                    "mean_reversion": 0.4,
                    "momentum": 0.1,
                    "value": 0.3,
                }
                strategy_params["rebalance_frequency"] = "monthly"
            elif parsed_requirement.risk_tolerance == RiskTolerance.AGGRESSIVE:
                strategy_params["strategy_mix"] = {
                    "trend_following": 0.4,
                    "mean_reversion": 0.1,
                    "momentum": 0.3,
                    "value": 0.2,
                }
                strategy_params["rebalance_frequency"] = "daily"

        # æ ¹æ®æ¨¡å‹è¾“å‡ºè°ƒæ•´
        if model_output.get("strategy_recommendation") == "growth":
            strategy_params["strategy_mix"]["momentum"] += 0.1
            strategy_params["strategy_mix"]["value"] -= 0.1

        return strategy_params

    def _generate_risk_parameters(
        self, parsed_requirement: ParsedRequirement
    ) -> Dict[str, Any]:
        """ç”Ÿæˆé£é™©å‚æ•°

        Args:
            parsed_requirement: è§£æåçš„éœ€æ±‚

        Returns:
            é£é™©å‚æ•°å­—å…¸
        """
        risk_params = {
            "max_drawdown": 0.15,
            "position_limit": 0.1,
            "leverage": 1.0,
            "stop_loss": 0.05,
        }

        # æ ¹æ®é£é™©åå¥½è°ƒæ•´
        if parsed_requirement.risk_tolerance:
            risk_tolerance_map = {
                RiskTolerance.CONSERVATIVE: {
                    "max_drawdown": 0.08,
                    "position_limit": 0.05,
                    "leverage": 1.0,
                    "stop_loss": 0.03,
                },
                RiskTolerance.MODERATE: {
                    "max_drawdown": 0.15,
                    "position_limit": 0.1,
                    "leverage": 1.0,
                    "stop_loss": 0.05,
                },
                RiskTolerance.AGGRESSIVE: {
                    "max_drawdown": 0.25,
                    "position_limit": 0.15,
                    "leverage": 1.5,
                    "stop_loss": 0.07,
                },
                RiskTolerance.VERY_AGGRESSIVE: {
                    "max_drawdown": 0.35,
                    "position_limit": 0.2,
                    "leverage": 2.0,
                    "stop_loss": 0.10,
                },
            }

            risk_params.update(
                risk_tolerance_map.get(parsed_requirement.risk_tolerance, {})
            )

        # æ ¹æ®æŠ•èµ„æœŸé™è°ƒæ•´
        if parsed_requirement.investment_horizon:
            horizon_map = {
                InvestmentHorizon.SHORT_TERM: {"stop_loss": 0.03},
                InvestmentHorizon.LONG_TERM: {"stop_loss": 0.08},
            }

            risk_params.update(
                horizon_map.get(parsed_requirement.investment_horizon, {})
            )

        return risk_params


# æ¨¡å—çº§åˆ«å‡½æ•°
async def process_investment_request(
    user_input: str, config: Dict[str, Any]
) -> Dict[str, Any]:
    """å¤„ç†æŠ•èµ„è¯·æ±‚çš„ä¾¿æ·å‡½æ•°

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        config: æ¨¡å‹é…ç½®

    Returns:
        å¤„ç†ç»“æœ
    """
    fin_r1 = FINR1Integration(config)
    return await fin_r1.process_request(user_input)
