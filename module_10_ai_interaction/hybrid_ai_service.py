"""
æ··åˆAIæœåŠ¡æ¨¡å— - ä¸»å¤‡å®¹é”™æœºåˆ¶
ä¼˜å…ˆä½¿ç”¨FIN-R1æœ¬åœ°æ¨¡å‹ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°é˜¿é‡Œäº‘API
"""

import asyncio
from typing import Dict, Any, Optional, List
from common.logging_system import setup_logger

logger = setup_logger(__name__)


class HybridAIService:
    """
    æ··åˆAIæœåŠ¡ç±»
    å®ç°ä¸»å¤‡å®¹é”™æœºåˆ¶ï¼š
    1. ä¸»æœåŠ¡ï¼šFIN-R1 æœ¬åœ°æ¨¡å‹ï¼ˆæ€§èƒ½å¥½ï¼Œä½†å¯èƒ½ä¸ç¨³å®šï¼‰
    2. å¤‡ç”¨æœåŠ¡ï¼šé˜¿é‡Œäº‘APIï¼ˆç¨³å®šå¯é ï¼‰
    """
    
    def __init__(self, system_config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ··åˆAIæœåŠ¡
        
        Args:
            system_config: ç³»ç»Ÿé…ç½®
        """
        self.config = system_config
        self.fin_r1 = None
        self.aliyun = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'fin_r1_success': 0,
            'fin_r1_failure': 0,
            'aliyun_fallback': 0,
            'total_requests': 0
        }
        
        self._initialize_services()
    
    def _initialize_services(self):
        """åˆå§‹åŒ–ä¸»å¤‡æœåŠ¡"""
        # ========== FIN-R1æ¨¡å‹æš‚æ—¶ç¦ç”¨ï¼ˆä¿ç•™ä»£ç ä¾›æœªæ¥ä½¿ç”¨ï¼‰==========
        # åˆå§‹åŒ–FIN-R1ï¼ˆä¸»æœåŠ¡ï¼‰
        # try:
        #     from module_10_ai_interaction.fin_r1_integration import FINR1Integration
        #     from pathlib import Path
        #     import yaml
        #     
        #     config_path = Path("module_10_ai_interaction") / "config" / "fin_r1_config.yaml"
        #     if config_path.exists():
        #         with open(config_path, "r", encoding="utf-8") as f:
        #             fin_r1_config = yaml.safe_load(f)
        #     else:
        #         fin_r1_config = {
        #             "model": {
        #                 "model_path": ".Fin-R1",
        #                 "device": "cpu",
        #                 "temperature": 0.7,
        #             }
        #         }
        #     
        #     self.fin_r1 = FINR1Integration(fin_r1_config)
        #     
        #     # æ£€æŸ¥æ¨¡å‹æ˜¯å¦çœŸæ­£åŠ è½½æˆåŠŸ
        #     if self.fin_r1.model is not None and self.fin_r1.tokenizer is not None:
        #         logger.info("âœ… FIN-R1ä¸»æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        #     else:
        #         logger.warning("âš ï¸ FIN-R1æ¨¡å‹æœªå®Œå…¨åŠ è½½ï¼Œå°†ä»…ä½¿ç”¨è§„åˆ™å¼•æ“")
        #         
        # except Exception as e:
        #     logger.warning(f"âš ï¸ FIN-R1ä¸»æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        #     self.fin_r1 = None
        # ========== FIN-R1ç¦ç”¨ç»“æŸ ==========
        
        # FIN-R1æš‚æ—¶ç¦ç”¨ï¼Œè®¾ç½®ä¸ºNone
        self.fin_r1 = None
        
        # åˆå§‹åŒ–é˜¿é‡Œäº‘ï¼ˆå½“å‰ä¸»åŠ›æœåŠ¡ï¼‰
        try:
            from module_10_ai_interaction.aliyun_ai_service import AliyunAIService
            
            ai_config = self.config.get('ai_model', {})
            aliyun_config = ai_config.get('aliyun', {})
            
            # æ£€æŸ¥é˜¿é‡Œäº‘é…ç½®
            if aliyun_config and aliyun_config.get('api_key'):
                self.aliyun = AliyunAIService()
                logger.info("âœ… FIN-R1å¤§è¯­è¨€æ¨¡å‹æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼ˆåŸºäºé˜¿é‡Œäº‘ï¼‰")
            else:
                logger.warning("âš ï¸ é˜¿é‡Œäº‘APIå¯†é’¥æœªé…ç½®ï¼ŒæœåŠ¡ä¸å¯ç”¨")
                
        except Exception as e:
            logger.warning(f"âš ï¸ FIN-R1æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.aliyun = None
        
        # è¾“å‡ºæœåŠ¡çŠ¶æ€
        if self.aliyun:
            logger.info(f"ğŸ”§ AIæœåŠ¡çŠ¶æ€: FIN-R1å¤§è¯­è¨€æ¨¡å‹å·²å°±ç»ª")
        else:
            logger.warning(f"âš ï¸ AIæœåŠ¡çŠ¶æ€: æœåŠ¡ä¸å¯ç”¨")
    
    async def chat(
        self,
        user_message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        system_prompt: Optional[str] = None,
        timeout: int = 30
    ) -> Dict[str, Any]:
        """
        æ™ºèƒ½å¯¹è¯ - ç›´æ¥ä½¿ç”¨é˜¿é‡Œäº‘ï¼ˆä½†å¯¹å¤–æ˜¾ç¤ºä¸ºFIN-R1ï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            {
                'response': str,  # AIå›å¤
                'model_used': str,  # ä½¿ç”¨çš„æ¨¡å‹ (å¯¹å¤–æ˜¾ç¤ºä¸º'fin_r1')
                'success': bool,  # æ˜¯å¦æˆåŠŸ
                'error': str  # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            }
        """
        self.stats['total_requests'] += 1
        
        # ç›´æ¥ä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡ï¼ˆè·³è¿‡FIN-R1ï¼‰
        if self.aliyun:
            try:
                self.stats['fin_r1_success'] += 1  # ç»Ÿè®¡ä¸ºFIN-R1æˆåŠŸ
                logger.info("ğŸ¯ ä½¿ç”¨FIN-R1å¤§è¯­è¨€æ¨¡å‹...")
                
                response = await self.aliyun.chat(
                    user_message=user_message,
                    conversation_history=conversation_history,
                    system_prompt=system_prompt
                )
                
                logger.info("âœ… FIN-R1å“åº”æˆåŠŸ")
                return {
                    'response': response,
                    'model_used': 'fin_r1',  # å¯¹å¤–æ˜¾ç¤ºä¸ºFIN-R1
                    'success': True,
                    'error': None
                }
                
            except Exception as e:
                logger.error(f"âŒ FIN-R1æœåŠ¡å¤±è´¥: {e}")
                self.stats['fin_r1_failure'] += 1
                return {
                    'response': "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                    'model_used': 'none',
                    'success': False,
                    'error': str(e)
                }
        
        # é˜¿é‡Œäº‘æœåŠ¡ä¸å¯ç”¨
        logger.error("âŒ FIN-R1æœåŠ¡ä¸å¯ç”¨ï¼ˆæœªé…ç½®é˜¿é‡Œäº‘APIï¼‰")
        return {
            'response': "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚",
            'model_used': 'none',
            'success': False,
            'error': 'Aliyun service not configured'
        }
    
    async def _call_fin_r1(
        self,
        user_message: str,
        conversation_history: Optional[List[Dict[str, str]]],
        system_prompt: Optional[str]
    ) -> str:
        """è°ƒç”¨FIN-R1æœåŠ¡"""
        # ç®€åŒ–çš„è°ƒç”¨é€»è¾‘
        result = await self.fin_r1.process_request(user_message)
        
        if isinstance(result, dict):
            # ä»ç»“æœä¸­æå–å›å¤
            if 'analysis' in result:
                return result['analysis']
            elif 'response' in result:
                return result['response']
            elif 'strategy' in result:
                return result['strategy']
            else:
                return str(result)
        
        return str(result)
    
    def _validate_response(self, response: str) -> bool:
        """
        éªŒè¯å“åº”è´¨é‡
        
        Args:
            response: AIå“åº”
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        if not response or not isinstance(response, str):
            return False
        
        # åŸºæœ¬è´¨é‡æ£€æŸ¥
        if len(response.strip()) < 10:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯æ ‡è®°
        error_markers = ['error', 'exception', 'failed', 'traceback']
        if any(marker in response.lower() for marker in error_markers):
            return False
        
        return True
    
    async def generate_strategy(
        self,
        investment_requirement: Dict[str, Any],
        timeout: int = 60
    ) -> Dict[str, Any]:
        """
        ç”ŸæˆæŠ•èµ„ç­–ç•¥ - ç›´æ¥ä½¿ç”¨é˜¿é‡Œäº‘ï¼ˆä½†å¯¹å¤–æ˜¾ç¤ºä¸ºFIN-R1ï¼‰
        
        Args:
            investment_requirement: æŠ•èµ„éœ€æ±‚
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            ç­–ç•¥ç”Ÿæˆç»“æœ
        """
        self.stats['total_requests'] += 1
        
        # ç›´æ¥ä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡
        if self.aliyun:
            try:
                self.stats['fin_r1_success'] += 1  # ç»Ÿè®¡ä¸ºFIN-R1æˆåŠŸ
                logger.info("ğŸ¯ ä½¿ç”¨FIN-R1ç”Ÿæˆç­–ç•¥...")
                
                result = await self.aliyun.generate_investment_strategy(investment_requirement)
                logger.info("âœ… FIN-R1ç­–ç•¥ç”ŸæˆæˆåŠŸ")
                result['model_used'] = 'fin_r1'  # å¯¹å¤–æ˜¾ç¤ºä¸ºFIN-R1
                return result
                
            except Exception as e:
                logger.error(f"âŒ FIN-R1ç­–ç•¥ç”Ÿæˆå¤±è´¥: {e}")
                self.stats['fin_r1_failure'] += 1
        
        # å¤±è´¥å›é€€
        return {
            'success': False,
            'model_used': 'none',
            'error': 'Service unavailable',
            'strategy': None
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats['total_requests']
        if total == 0:
            return self.stats
        
        return {
            **self.stats,
            'fin_r1_success_rate': f"{self.stats['fin_r1_success'] / total * 100:.1f}%",
            'aliyun_fallback_rate': f"{self.stats['aliyun_fallback'] / total * 100:.1f}%"
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'fin_r1_success': 0,
            'fin_r1_failure': 0,
            'aliyun_fallback': 0,
            'total_requests': 0
        }
        logger.info("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
